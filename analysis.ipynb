{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T16:15:24.862242Z",
     "iopub.status.busy": "2025-03-30T16:15:24.861984Z",
     "iopub.status.idle": "2025-03-30T16:15:29.302345Z",
     "shell.execute_reply": "2025-03-30T16:15:29.301594Z",
     "shell.execute_reply.started": "2025-03-30T16:15:24.862217Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /usr/share/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!export CUDA_LAUNCH_BLOCKING=1\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time, re, pickle\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.tokenize import TreebankWordTokenizer, casual_tokenize\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "nltk.download('brown')\n",
    "nltk.download('punkt')\n",
    "import sys\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T16:15:29.303562Z",
     "iopub.status.busy": "2025-03-30T16:15:29.303175Z",
     "iopub.status.idle": "2025-03-30T16:15:29.309933Z",
     "shell.execute_reply": "2025-03-30T16:15:29.309143Z",
     "shell.execute_reply.started": "2025-03-30T16:15:29.303528Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "##############################\n",
    "\n",
    "##############################\n",
    "class ELMoBiLM(nn.Module):\n",
    "    \"\"\"\n",
    "    This ELMo model does NOT combine e0, e1, e2.\n",
    "    It just provides them separately:\n",
    "      - e0: input embeddings\n",
    "      - e1: forward hidden states\n",
    "      - e2: backward hidden states\n",
    "    We'll do the combination in the downstream classification step.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=2, pretrained_embeddings=None):\n",
    "        super(ELMoBiLM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        if pretrained_embeddings is not None:\n",
    "            self.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "        self.lstm1 = nn.LSTM(\n",
    "            embed_dim, hidden_dim, num_layers=num_layers,\n",
    "            batch_first=True, bidirectional=True\n",
    "        )\n",
    "        self.lstm2 = nn.LSTM(\n",
    "            hidden_dim*2, hidden_dim, num_layers=num_layers,\n",
    "            batch_first=True, bidirectional=True\n",
    "        )\n",
    "        self.forward_linear = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.backward_linear = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        emb = self.embedding(input_ids)  \n",
    "        outputs1, _ = self.lstm1(emb)      \n",
    "        outputs2, _ = self.lstm2(outputs1)\n",
    "        hf = outputs2[:, :, :outputs2.size(2)//2]   \n",
    "        hb = outputs2[:, :, outputs2.size(2)//2:]   \n",
    "        \n",
    "        forward_logits = self.forward_linear(hf)\n",
    "        backward_logits = self.backward_linear(hb)\n",
    "        return forward_logits, backward_logits, (emb, hf, hb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T16:15:29.311094Z",
     "iopub.status.busy": "2025-03-30T16:15:29.310810Z",
     "iopub.status.idle": "2025-03-30T16:15:29.331926Z",
     "shell.execute_reply": "2025-03-30T16:15:29.331117Z",
     "shell.execute_reply.started": "2025-03-30T16:15:29.311066Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self):\n",
    "        self.treebank_tokenizer = TreebankWordTokenizer()\n",
    "        \n",
    "    def preprocess_special_cases(self, text):\n",
    "        text = re.sub(r'https?://\\S+|www\\.\\S+', 'URL', text)\n",
    "        text = re.sub(r'#\\w+', 'HASHTAG', text)\n",
    "        text = re.sub(r'@\\w+', 'MENTION', text)\n",
    "        text = re.sub(r'\\b\\d+%|\\b\\d+\\s?percent\\b', 'PERCENTAGE', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\b\\d+\\s?(years old|yo|yrs|yr)\\b', 'AGE', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\b\\d{1,2}:\\d{2}\\s?(AM|PM|am|pm)?\\b', 'TIME', text)\n",
    "        text = re.sub(r'\\b\\d+\\s?(hours|hrs|minutes|mins|seconds|secs|days|weeks|months|years)\\b', 'TIMEPERIOD', text, flags=re.IGNORECASE)\n",
    "        return text\n",
    "    \n",
    "    def custom_sentence_split(self, text):\n",
    "        abbreviations = [\n",
    "            \"Mr.\", \"Dr.\", \"Ms.\", \"Mrs.\", \"Prof.\", \"Sr.\", \"Jr.\", \"Ph.D.\", \"M.D.\",\n",
    "            \"B.A.\", \"M.A.\", \"D.D.S.\", \"D.V.M.\", \"LL.D.\", \"B.C.\", \"a.m.\", \"p.m.\",\n",
    "            \"etc.\", \"e.g.\", \"i.e.\", \"vs.\", \"Jan.\", \"Feb.\", \"Mar.\", \"Apr.\", \"Jun.\",\n",
    "            \"Jul.\", \"Aug.\", \"Sep.\", \"Oct.\", \"Nov.\", \"Dec.\"\n",
    "        ]\n",
    "        for abbr in abbreviations:\n",
    "            text = text.replace(abbr, abbr.replace(\".\", \"<DOT>\"))\n",
    "        sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "        sentences = [s.replace(\"<DOT>\", \".\") for s in sentences]\n",
    "        return sentences\n",
    "\n",
    "    def preprocess(self, text):\n",
    "        text = self.preprocess_special_cases(text)\n",
    "        sentences = self.custom_sentence_split(text)\n",
    "        tokenized_sentences = []\n",
    "        for sentence in sentences:\n",
    "            casual_tokens = casual_tokenize(sentence, preserve_case=True)\n",
    "            tokens = []\n",
    "            for token in casual_tokens:\n",
    "                tokens.extend(self.treebank_tokenizer.tokenize(token))\n",
    "            tokenized_sentences.append(self.add_special_tokens(tokens))\n",
    "        return tokenized_sentences\n",
    "\n",
    "    def add_special_tokens(self, tokens):\n",
    "        return ['START'] + tokens + ['END']\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        return self.preprocess(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T16:15:29.333550Z",
     "iopub.status.busy": "2025-03-30T16:15:29.333333Z",
     "iopub.status.idle": "2025-03-30T16:15:29.732681Z",
     "shell.execute_reply": "2025-03-30T16:15:29.732031Z",
     "shell.execute_reply.started": "2025-03-30T16:15:29.333531Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Tokenizer:\n",
    "    def __init__(self):\n",
    "        self.treebank_tokenizer = TreebankWordTokenizer()\n",
    "        \n",
    "    def preprocess_special_cases(self, text):\n",
    "        text = re.sub(r'https?://\\S+|www\\.\\S+', 'URL', text)\n",
    "        text = re.sub(r'#\\w+', 'HASHTAG', text)\n",
    "        text = re.sub(r'@\\w+', 'MENTION', text)\n",
    "        text = re.sub(r'\\b\\d+%|\\b\\d+\\s?percent\\b', 'PERCENTAGE', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\b\\d+\\s?(years old|yo|yrs|yr)\\b', 'AGE', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\b\\d{1,2}:\\d{2}\\s?(AM|PM|am|pm)?\\b', 'TIME', text)\n",
    "        text = re.sub(r'\\b\\d+\\s?(hours|hrs|minutes|mins|seconds|secs|days|weeks|months|years)\\b', 'TIMEPERIOD', text, flags=re.IGNORECASE)\n",
    "        return text\n",
    "    \n",
    "    def custom_sentence_split(self, text):\n",
    "        abbreviations = [\n",
    "            \"Mr.\", \"Dr.\", \"Ms.\", \"Mrs.\", \"Prof.\", \"Sr.\", \"Jr.\", \"Ph.D.\", \"M.D.\",\n",
    "            \"B.A.\", \"M.A.\", \"D.D.S.\", \"D.V.M.\", \"LL.D.\", \"B.C.\", \"a.m.\", \"p.m.\",\n",
    "            \"etc.\", \"e.g.\", \"i.e.\", \"vs.\", \"Jan.\", \"Feb.\", \"Mar.\", \"Apr.\", \"Jun.\",\n",
    "            \"Jul.\", \"Aug.\", \"Sep.\", \"Oct.\", \"Nov.\", \"Dec.\"\n",
    "        ]\n",
    "        for abbr in abbreviations:\n",
    "            text = text.replace(abbr, abbr.replace(\".\", \"<DOT>\"))\n",
    "        sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "        sentences = [s.replace(\"<DOT>\", \".\") for s in sentences]\n",
    "        return sentences\n",
    "\n",
    "    def preprocess(self, text):\n",
    "        text = self.preprocess_special_cases(text)\n",
    "        sentences = self.custom_sentence_split(text)\n",
    "        tokenized_sentences = []\n",
    "        for sentence in sentences:\n",
    "            casual_tokens = casual_tokenize(sentence, preserve_case=True)\n",
    "            tokens = []\n",
    "            for token in casual_tokens:\n",
    "                tokens.extend(self.treebank_tokenizer.tokenize(token))\n",
    "            tokenized_sentences.append(self.add_special_tokens(tokens))\n",
    "        return tokenized_sentences\n",
    "\n",
    "    def add_special_tokens(self, tokens):\n",
    "        return ['START'] + tokens + ['END']\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        return self.preprocess(text)\n",
    "\n",
    "def sentence_to_indices(sentence, vocab):\n",
    "    return [vocab.get(token, vocab[\"<unk>\"]) for token in sentence]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FrozenLambdaElmoClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, elmo_model, num_classes, rnn_hidden_size=128, rnn_layers=1, fixed_lambdas=None):\n",
    "        super(FrozenLambdaElmoClassifier, self).__init__()\n",
    "        self.elmo = elmo_model\n",
    "        for param in self.elmo.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.embed_dim = self.elmo.embedding.embedding_dim  \n",
    "        self.hidden_dim = self.elmo.lstm1.hidden_size         \n",
    "\n",
    "        if self.embed_dim != self.hidden_dim:\n",
    "            self.e0_proj = nn.Linear(self.embed_dim, self.hidden_dim)\n",
    "        else:\n",
    "            self.e0_proj = nn.Identity()\n",
    "\n",
    "        if fixed_lambdas is None:\n",
    "            self.lambdas = [1/3, 1/3, 1/3]\n",
    "        else:\n",
    "            self.lambdas = fixed_lambdas\n",
    "\n",
    "        self.classifier_rnn = nn.LSTM(input_size=self.hidden_dim,\n",
    "                                      hidden_size=rnn_hidden_size,\n",
    "                                      num_layers=rnn_layers,\n",
    "                                      batch_first=True)\n",
    "        self.fc = nn.Linear(rnn_hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        _, _, (emb, hf, hb) = self.elmo(input_ids)\n",
    "        e0 = self.e0_proj(emb)\n",
    "        e1 = hf\n",
    "        e2 = hb\n",
    "        combined = self.lambdas[0] * e0 + self.lambdas[1] * e1 + self.lambdas[2] * e2\n",
    "        rnn_out, (h_n, _) = self.classifier_rnn(combined)\n",
    "        last_hidden = h_n[-1]\n",
    "        logits = self.fc(last_hidden)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class TrainableLambdaElmoClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, elmo_model, num_classes, rnn_hidden_size=128, rnn_layers=1):\n",
    "        super(TrainableLambdaElmoClassifier, self).__init__()\n",
    "        self.elmo = elmo_model\n",
    "        for param in self.elmo.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.embed_dim = self.elmo.embedding.embedding_dim\n",
    "        self.hidden_dim = self.elmo.lstm1.hidden_size\n",
    "\n",
    "        if self.embed_dim != self.hidden_dim:\n",
    "            self.e0_proj = nn.Linear(self.embed_dim, self.hidden_dim)\n",
    "        else:\n",
    "            self.e0_proj = nn.Identity()\n",
    "\n",
    "        self.lambda_params = nn.Parameter(torch.zeros(3))\n",
    "\n",
    "        self.classifier_rnn = nn.LSTM(input_size=self.hidden_dim,\n",
    "                                      hidden_size=rnn_hidden_size,\n",
    "                                      num_layers=rnn_layers,\n",
    "                                      batch_first=True)\n",
    "        self.fc = nn.Linear(rnn_hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        _, _, (emb, hf, hb) = self.elmo(input_ids)\n",
    "        e0 = self.e0_proj(emb)\n",
    "        e1 = hf\n",
    "        e2 = hb\n",
    "        lambdas = torch.softmax(self.lambda_params, dim=0)\n",
    "        combined = lambdas[0] * e0 + lambdas[1] * e1 + lambdas[2] * e2\n",
    "        rnn_out, (h_n, _) = self.classifier_rnn(combined)\n",
    "        last_hidden = h_n[-1]\n",
    "        logits = self.fc(last_hidden)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class LearnableFunctionElmoClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, elmo_model, num_classes, rnn_hidden_size=128, rnn_layers=1):\n",
    "        super(LearnableFunctionElmoClassifier, self).__init__()\n",
    "        self.elmo = elmo_model\n",
    "        for param in self.elmo.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.embed_dim = self.elmo.embedding.embedding_dim\n",
    "        self.hidden_dim = self.elmo.lstm1.hidden_size\n",
    "\n",
    "        \n",
    "        if self.embed_dim != self.hidden_dim:\n",
    "            self.e0_proj = nn.Linear(self.embed_dim, self.hidden_dim)\n",
    "        else:\n",
    "            self.e0_proj = nn.Identity()\n",
    "\n",
    "        self.mlp_combiner = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim * 3, self.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "\n",
    "        self.classifier_rnn = nn.LSTM(input_size=self.hidden_dim,\n",
    "                                      hidden_size=rnn_hidden_size,\n",
    "                                      num_layers=rnn_layers,\n",
    "                                      batch_first=True)\n",
    "        self.fc = nn.Linear(rnn_hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            _, _, (emb, hf, hb) = self.elmo(input_ids)\n",
    "        e0 = self.e0_proj(emb)  \n",
    "        e1 = hf               \n",
    "        e2 = hb               \n",
    "\n",
    "        \n",
    "        concatenated = torch.cat([e0, e1, e2], dim=2)  \n",
    "        \n",
    "        combined_token = self.mlp_combiner(concatenated)  \n",
    "\n",
    "        \n",
    "        rnn_out, (h_n, _) = self.classifier_rnn(combined_token)\n",
    "        last_hidden = h_n[-1]  \n",
    "        logits = self.fc(last_hidden)\n",
    "        return logits\n",
    "\n",
    "\n",
    "\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, dataframe, vocab, tokenizer):\n",
    "        self.data = dataframe\n",
    "        self.vocab = vocab\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.iloc[idx]['Description']\n",
    "        label = self.data.iloc[idx]['Class Index']-1\n",
    "        \n",
    "        tokenized_sentences = self.tokenizer.tokenize(text)\n",
    "        \n",
    "        tokens = [token for sentence in tokenized_sentences for token in sentence]\n",
    "        indices = sentence_to_indices(tokens, self.vocab)\n",
    "        return indices, label\n",
    "\n",
    "def collate_classification(batch):\n",
    "    pad_idx = 0\n",
    "    max_len = max(len(x[0]) for x in batch)\n",
    "    input_batch, label_batch = [], []\n",
    "    for input_ids, label in batch:\n",
    "        seq_len = len(input_ids)\n",
    "        pad_tensor = torch.full((max_len - seq_len,), pad_idx, dtype=torch.long)\n",
    "        input_tensor = torch.tensor(input_ids, dtype=torch.long)\n",
    "        input_batch.append(torch.cat([input_tensor, pad_tensor]))\n",
    "        label_batch.append(label)\n",
    "    return torch.stack(input_batch), torch.tensor(label_batch, dtype=torch.long)\n",
    "\n",
    "\n",
    "def train_classifier(model, dataloader, device, epochs=3, lr=1e-3):\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        total_correct = 0\n",
    "        total_examples = 0\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}\")\n",
    "        for inputs, labels in pbar:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(inputs)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix(loss=f\"{total_loss/len(dataloader):.4f}\")\n",
    "            predictions = logits.argmax(dim=1)\n",
    "            total_correct += (predictions == labels).sum().item()\n",
    "            total_examples += labels.size(0)\n",
    "        acc = total_correct / total_examples\n",
    "        avg_loss = total_loss/len(dataloader)\n",
    "        print(f\"Epoch {epoch+1} finished. Loss: {avg_loss:.4f}, Training Accuracy: {acc*100:.2f}%\")\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    EMBED_DIM = 100\n",
    "    HIDDEN_DIM = 256\n",
    "    NUM_LAYERS = 2\n",
    "    BATCH_SIZE = 32\n",
    "    CLASSIFIER_EPOCHS = 10\n",
    "    LEARNING_RATE = 1e-3\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    vocab_path = \"/kaggle/input/idk/pytorch/default/1/vocab.pkl\"\n",
    "    bilstm_path = \"/kaggle/input/idk/pytorch/default/1/bilstm.pt\"\n",
    "    if not os.path.exists(vocab_path):\n",
    "        raise FileNotFoundError(f\"Vocabulary file not found at {vocab_path}\")\n",
    "    if not os.path.exists(bilstm_path):\n",
    "        raise FileNotFoundError(f\"Pre-trained ELMo model not found at {bilstm_path}\")\n",
    "\n",
    "    with open(vocab_path, \"rb\") as f:\n",
    "        vocab = pickle.load(f)\n",
    "    vocab_size = len(vocab)\n",
    "    elmo_model = ELMoBiLM(vocab_size, EMBED_DIM, HIDDEN_DIM, num_layers=NUM_LAYERS)\n",
    "    elmo_model.load_state_dict(torch.load(bilstm_path, map_location=device))\n",
    "    elmo_model.eval()\n",
    "\n",
    "    csv_path = \"/kaggle/input/news-classification/train.csv\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    tokenizer = Tokenizer()\n",
    "    news_dataset = NewsDataset(df, vocab, tokenizer)\n",
    "    news_dataloader = DataLoader(news_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_classification, num_workers=4, pin_memory=True)\n",
    "\n",
    "    num_classes = df['Class Index'].nunique()\n",
    "    classifiers = {\n",
    "        \"frozen\": FrozenLambdaElmoClassifier(elmo_model, num_classes=num_classes),\n",
    "        \"trainable\": TrainableLambdaElmoClassifier(elmo_model, num_classes=num_classes),\n",
    "        \"learnable\": LearnableFunctionElmoClassifier(elmo_model, num_classes=num_classes)\n",
    "    }\n",
    "\n",
    "    for method_name, classifier in classifiers.items():\n",
    "        print(f\"\\nTraining classifier with method: {method_name}\")\n",
    "        classifier = train_classifier(classifier, news_dataloader, device, epochs=CLASSIFIER_EPOCHS, lr=LEARNING_RATE)\n",
    "        save_path = f\"classifier_{method_name}.pt\"\n",
    "        torch.save(classifier.state_dict(), save_path)\n",
    "        print(f\"Saved {method_name} classifier to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T16:15:54.473115Z",
     "iopub.status.busy": "2025-03-30T16:15:54.472791Z",
     "iopub.status.idle": "2025-03-30T16:15:54.492794Z",
     "shell.execute_reply": "2025-03-30T16:15:54.491900Z",
     "shell.execute_reply.started": "2025-03-30T16:15:54.473086Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_static_embedding_model(filepath, device):\n",
    "    state = torch.load(filepath, map_location=device, weights_only=True)\n",
    "    embeddings_dict = state[\"embeddings\"]\n",
    "    word_to_index = state[\"word_to_index\"]\n",
    "    vocab_size = len(word_to_index)\n",
    "    \n",
    "    sample_vec = next(iter(embeddings_dict.values()))\n",
    "    embed_dim = len(sample_vec)\n",
    "    \n",
    "    embedding_matrix = torch.zeros(vocab_size, embed_dim)\n",
    "    for word, idx in word_to_index.items():\n",
    "        if word in embeddings_dict:\n",
    "            vec = embeddings_dict[word]\n",
    "        else:\n",
    "            vec = [0.0] * embed_dim\n",
    "        embedding_matrix[idx] = torch.tensor(vec, dtype=torch.float)\n",
    "    embedding_layer = nn.Embedding(vocab_size, embed_dim)\n",
    "    embedding_layer.weight.data.copy_(embedding_matrix)\n",
    "    embedding_layer.weight.requires_grad = False  \n",
    "\n",
    "    \n",
    "    class StaticEmbeddingWrapper(nn.Module):\n",
    "        def __init__(self, embedding, vocab):\n",
    "            super().__init__()\n",
    "            self.embedding = embedding\n",
    "            self.vocab = vocab\n",
    "    return StaticEmbeddingWrapper(embedding_layer, word_to_index).to(device)\n",
    "\n",
    "\n",
    "def sentence_to_indices(sentence, vocab):\n",
    "    return [vocab.get(token, vocab.get(\"<unk>\", 1)) for token in sentence]\n",
    "\n",
    "class NewsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    News classification dataset reading from a CSV file.\n",
    "    Assumes the CSV file has columns 'text' and 'label'.\n",
    "    Uses the given tokenizer and vocabulary.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe, vocab, tokenizer):\n",
    "        self.data = dataframe\n",
    "        self.vocab = vocab\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.iloc[idx]['Description']\n",
    "        label = self.data.iloc[idx]['Class Index']-1\n",
    "        tokenized_sentences = self.tokenizer.tokenize(text)\n",
    "        tokens = [token for sentence in tokenized_sentences for token in sentence]\n",
    "        indices = sentence_to_indices(tokens, self.vocab)\n",
    "        return indices, label\n",
    "\n",
    "def collate_classification(batch):\n",
    "    pad_idx = 0\n",
    "    max_len = max(len(x[0]) for x in batch)\n",
    "    input_batch, label_batch = [], []\n",
    "    for input_ids, label in batch:\n",
    "        seq_len = len(input_ids)\n",
    "        pad_tensor = torch.full((max_len - seq_len,), pad_idx, dtype=torch.long)\n",
    "        input_tensor = torch.tensor(input_ids, dtype=torch.long)\n",
    "        input_batch.append(torch.cat([input_tensor, pad_tensor]))\n",
    "        label_batch.append(label)\n",
    "    return torch.stack(input_batch), torch.tensor(label_batch, dtype=torch.long)\n",
    "\n",
    "class CBOWClassifier(nn.Module):\n",
    "    def __init__(self, static_model, num_classes, rnn_hidden_size=128, rnn_layers=1):\n",
    "        super(CBOWClassifier, self).__init__()\n",
    "        self.embedding = static_model.embedding\n",
    "        for param in self.embedding.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.vocab = static_model.vocab\n",
    "        embed_dim = self.embedding.embedding_dim\n",
    "        self.rnn = nn.LSTM(input_size=embed_dim,\n",
    "                           hidden_size=rnn_hidden_size,\n",
    "                           num_layers=rnn_layers,\n",
    "                           batch_first=True)\n",
    "        self.fc = nn.Linear(rnn_hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, input_ids):\n",
    "        emb = self.embedding(input_ids)  \n",
    "        _, (h_n, _) = self.rnn(emb)\n",
    "        last_hidden = h_n[-1]\n",
    "        logits = self.fc(last_hidden)\n",
    "        return logits\n",
    "\n",
    "class SkipgramClassifier(nn.Module):\n",
    "    def __init__(self, static_model, num_classes, rnn_hidden_size=128, rnn_layers=1):\n",
    "        super(SkipgramClassifier, self).__init__()\n",
    "        self.embedding = static_model.embedding\n",
    "        for param in self.embedding.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.vocab = static_model.vocab\n",
    "        embed_dim = self.embedding.embedding_dim\n",
    "        self.rnn = nn.LSTM(input_size=embed_dim,\n",
    "                           hidden_size=rnn_hidden_size,\n",
    "                           num_layers=rnn_layers,\n",
    "                           batch_first=True)\n",
    "        self.fc = nn.Linear(rnn_hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, input_ids):\n",
    "        emb = self.embedding(input_ids)\n",
    "        _, (h_n, _) = self.rnn(emb)\n",
    "        last_hidden = h_n[-1]\n",
    "        logits = self.fc(last_hidden)\n",
    "        return logits\n",
    "\n",
    "class SVDClassifier(nn.Module):\n",
    "    def __init__(self, static_model, num_classes, rnn_hidden_size=128, rnn_layers=1):\n",
    "        super(SVDClassifier, self).__init__()\n",
    "        self.embedding = static_model.embedding\n",
    "        for param in self.embedding.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.vocab = static_model.vocab\n",
    "        embed_dim = self.embedding.embedding_dim\n",
    "        self.rnn = nn.LSTM(input_size=embed_dim,\n",
    "                           hidden_size=rnn_hidden_size,\n",
    "                           num_layers=rnn_layers,\n",
    "                           batch_first=True)\n",
    "        self.fc = nn.Linear(rnn_hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, input_ids):\n",
    "        emb = self.embedding(input_ids)\n",
    "        _, (h_n, _) = self.rnn(emb)\n",
    "        last_hidden = h_n[-1]\n",
    "        logits = self.fc(last_hidden)\n",
    "        return logits\n",
    "\n",
    "\n",
    "def train_classifier(model, dataloader, device, epochs=3, lr=1e-3):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_examples = 0\n",
    "        pbar = tqdm(dataloader, desc=f\"Classifier Training Epoch {epoch+1}\")\n",
    "        for inputs, labels in pbar:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(inputs)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix(loss=f\"{total_loss/len(dataloader):.4f}\")\n",
    "            predictions = logits.argmax(dim=1)\n",
    "            total_correct += (predictions == labels).sum().item()\n",
    "            total_examples += labels.size(0)\n",
    "        acc = total_correct / total_examples\n",
    "        avg_loss = total_loss/len(dataloader)\n",
    "        print(f\"Epoch {epoch+1} finished. Loss: {avg_loss:.4f}, Training Accuracy: {acc*100:.2f}%\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T17:39:27.075210Z",
     "iopub.status.busy": "2025-03-30T17:39:27.074823Z",
     "iopub.status.idle": "2025-03-30T17:51:12.088055Z",
     "shell.execute_reply": "2025-03-30T17:51:12.086956Z",
     "shell.execute_reply.started": "2025-03-30T17:39:27.075174Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-39855d653ebf>:88: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  elmo_model.load_state_dict(torch.load(bilstm_path, map_location=device))\n",
      "<ipython-input-10-39855d653ebf>:100: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ELMo-based Classifiers Evaluation ===\n",
      "\n",
      "--- Model: frozen ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Metrics:\n",
      "Accuracy : 0.9239\n",
      "Precision: 0.9257\n",
      "Recall   : 0.9239\n",
      "F1 Score : 0.9241\n",
      "Confusion Matrix:\n",
      "[[27344   631   743  1282]\n",
      " [  168 29339   117   376]\n",
      " [  480   175 26272  3073]\n",
      " [  466   229  1390 27915]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Metrics:\n",
      "Accuracy : 0.8450\n",
      "Precision: 0.8477\n",
      "Recall   : 0.8450\n",
      "F1 Score : 0.8455\n",
      "Confusion Matrix:\n",
      "[[1600   80   84  136]\n",
      " [  38 1760   24   78]\n",
      " [  72   34 1490  304]\n",
      " [  65   65  198 1572]]\n",
      "\n",
      "--- Model: trainable ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Metrics:\n",
      "Accuracy : 0.9345\n",
      "Precision: 0.9346\n",
      "Recall   : 0.9345\n",
      "F1 Score : 0.9344\n",
      "Confusion Matrix:\n",
      "[[28020   504   775   701]\n",
      " [  323 29373   112   192]\n",
      " [  517   224 27079  2180]\n",
      " [  687   288  1359 27666]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Metrics:\n",
      "Accuracy : 0.8501\n",
      "Precision: 0.8499\n",
      "Recall   : 0.8501\n",
      "F1 Score : 0.8499\n",
      "Confusion Matrix:\n",
      "[[1615   83  107   95]\n",
      " [  64 1756   40   40]\n",
      " [  98   41 1525  236]\n",
      " [  96   64  175 1565]]\n",
      "\n",
      "--- Model: learnable ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Metrics:\n",
      "Accuracy : 0.8921\n",
      "Precision: 0.8927\n",
      "Recall   : 0.8921\n",
      "F1 Score : 0.8919\n",
      "Confusion Matrix:\n",
      "[[26677   927  1076  1320]\n",
      " [  348 29037   168   447]\n",
      " [  924   479 24994  3603]\n",
      " [ 1063   607  1987 26343]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Metrics:\n",
      "Accuracy : 0.8582\n",
      "Precision: 0.8587\n",
      "Recall   : 0.8582\n",
      "F1 Score : 0.8578\n",
      "Confusion Matrix:\n",
      "[[1639   79   80  102]\n",
      " [  38 1798   22   42]\n",
      " [  76   46 1501  277]\n",
      " [  85   62  169 1584]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-39855d653ebf>:163: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Static Embedding Classifiers Evaluation ===\n",
      "\n",
      "--- Model: cbow ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Metrics:\n",
      "Accuracy : 0.8662\n",
      "Precision: 0.8671\n",
      "Recall   : 0.8662\n",
      "F1 Score : 0.8650\n",
      "Confusion Matrix:\n",
      "[[25357  1918  1656  1069]\n",
      " [  358 28972   250   420]\n",
      " [  822   663 26410  2105]\n",
      " [ 1657  1318  3822 23203]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Metrics:\n",
      "Accuracy : 0.7875\n",
      "Precision: 0.7882\n",
      "Recall   : 0.7875\n",
      "F1 Score : 0.7856\n",
      "Confusion Matrix:\n",
      "[[1442  174  163  121]\n",
      " [  69 1739   31   61]\n",
      " [  99   73 1525  203]\n",
      " [ 123  146  352 1279]]\n",
      "\n",
      "--- Model: skipgram ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Metrics:\n",
      "Accuracy : 0.9166\n",
      "Precision: 0.9170\n",
      "Recall   : 0.9166\n",
      "F1 Score : 0.9168\n",
      "Confusion Matrix:\n",
      "[[27593   609   735  1063]\n",
      " [  498 28659   373   470]\n",
      " [  754   203 27008  2035]\n",
      " [  845   207  2212 26736]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Metrics:\n",
      "Accuracy : 0.8333\n",
      "Precision: 0.8338\n",
      "Recall   : 0.8333\n",
      "F1 Score : 0.8335\n",
      "Confusion Matrix:\n",
      "[[1598   88  106  108]\n",
      " [  80 1704   55   61]\n",
      " [ 106   31 1540  223]\n",
      " [ 100   53  256 1491]]\n",
      "\n",
      "--- Model: svd ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Metrics:\n",
      "Accuracy : 0.6615\n",
      "Precision: 0.6806\n",
      "Recall   : 0.6615\n",
      "F1 Score : 0.6616\n",
      "Confusion Matrix:\n",
      "[[18618  3170  2075  6137]\n",
      " [ 2342 23636   301  3721]\n",
      " [ 3527  1211 15257 10005]\n",
      " [ 2913  1961  3256 21870]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Metrics:\n",
      "Accuracy : 0.6438\n",
      "Precision: 0.6588\n",
      "Recall   : 0.6438\n",
      "F1 Score : 0.6427\n",
      "Confusion Matrix:\n",
      "[[1116  239  153  392]\n",
      " [ 169 1494   15  222]\n",
      " [ 236   87  940  637]\n",
      " [ 176  147  234 1343]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.numpy())\n",
    "    return all_labels, all_preds\n",
    "\n",
    "def load_static_embedding_model(filepath, device):\n",
    "    state = torch.load(filepath, map_location=device, weights_only=True)\n",
    "    embeddings_dict = state[\"embeddings\"]\n",
    "    word_to_index = state[\"word_to_index\"]\n",
    "    vocab_size = len(word_to_index)\n",
    "    sample_vec = next(iter(embeddings_dict.values()))\n",
    "    embed_dim = len(sample_vec)\n",
    "    embedding_matrix = torch.zeros(vocab_size, embed_dim)\n",
    "    for word, idx in word_to_index.items():\n",
    "        vec = embeddings_dict[word] if word in embeddings_dict else [0.0] * embed_dim\n",
    "        embedding_matrix[idx] = torch.tensor(vec, dtype=torch.float)\n",
    "    embedding_layer = nn.Embedding(vocab_size, embed_dim)\n",
    "    embedding_layer.weight.data.copy_(embedding_matrix)\n",
    "    embedding_layer.weight.requires_grad = False\n",
    "    class StaticEmbeddingWrapper(nn.Module):\n",
    "        def __init__(self, embedding, vocab):\n",
    "            super().__init__()\n",
    "            self.embedding = embedding\n",
    "            self.vocab = vocab\n",
    "    return StaticEmbeddingWrapper(embedding_layer, word_to_index).to(device)\n",
    "\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    train_csv_path = \"/kaggle/input/news-classification/train.csv\"\n",
    "    test_csv_path = \"/kaggle/input/news-classification/test.csv\"  \n",
    "    train_df = pd.read_csv(train_csv_path)\n",
    "    test_df = pd.read_csv(test_csv_path)\n",
    "    \n",
    "    tokenizer = Tokenizer()\n",
    "    \n",
    "    num_classes = train_df['Class Index'].nunique()\n",
    "\n",
    "    vocab_path = \"/kaggle/input/idk/pytorch/default/1/vocab.pkl\"\n",
    "    bilstm_path = \"/kaggle/input/idk/pytorch/default/1/bilstm.pt\"\n",
    "    with open(vocab_path, \"rb\") as f:\n",
    "        vocab = pickle.load(f)\n",
    "    vocab_size = len(vocab)\n",
    "    EMBED_DIM = 100\n",
    "    HIDDEN_DIM = 256\n",
    "    NUM_LAYERS = 2\n",
    "\n",
    "    elmo_model = ELMoBiLM(vocab_size, EMBED_DIM, HIDDEN_DIM, num_layers=NUM_LAYERS)\n",
    "    elmo_model.load_state_dict(torch.load(bilstm_path, map_location=device))\n",
    "    elmo_model.eval()\n",
    "    \n",
    "    elmo_classifiers = {\n",
    "        \"frozen\": FrozenLambdaElmoClassifier(elmo_model, num_classes=num_classes),\n",
    "        \"trainable\": TrainableLambdaElmoClassifier(elmo_model, num_classes=num_classes),\n",
    "        \"learnable\": LearnableFunctionElmoClassifier(elmo_model, num_classes=num_classes)\n",
    "    }\n",
    "    for name, model in elmo_classifiers.items():\n",
    "        model_path = f\"/kaggle/input/newmodels/pytorch/default/1/classifier2_{name}.pt\"\n",
    "        state_dict = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.to(device)\n",
    "    \n",
    "    dataset_train_elmo = NewsDataset(train_df, vocab, tokenizer)\n",
    "    dataset_test_elmo = NewsDataset(test_df, vocab, tokenizer)\n",
    "    loader_train_elmo = DataLoader(dataset_train_elmo, batch_size=32, shuffle=False, collate_fn=collate_classification, num_workers=4)\n",
    "    loader_test_elmo = DataLoader(dataset_test_elmo, batch_size=32, shuffle=False, collate_fn=collate_classification, num_workers=4)\n",
    "    \n",
    "    print(\"=== ELMo-based Classifiers Evaluation ===\")\n",
    "    for name, model in elmo_classifiers.items():\n",
    "        print(f\"\\n--- Model: {name} ---\")\n",
    "        \n",
    "        true_train, pred_train = evaluate_model(model, loader_train_elmo, device)\n",
    "        acc_train = accuracy_score(true_train, pred_train)\n",
    "        prec_train = precision_score(true_train, pred_train, average='macro', zero_division=0)\n",
    "        rec_train = recall_score(true_train, pred_train, average='macro', zero_division=0)\n",
    "        f1_train = f1_score(true_train, pred_train, average='macro', zero_division=0)\n",
    "        cm_train = confusion_matrix(true_train, pred_train)\n",
    "        print(\"Train Metrics:\")\n",
    "        print(f\"Accuracy : {acc_train:.4f}\")\n",
    "        print(f\"Precision: {prec_train:.4f}\")\n",
    "        print(f\"Recall   : {rec_train:.4f}\")\n",
    "        print(f\"F1 Score : {f1_train:.4f}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(cm_train)\n",
    "        \n",
    "        \n",
    "        true_test, pred_test = evaluate_model(model, loader_test_elmo, device)\n",
    "        acc_test = accuracy_score(true_test, pred_test)\n",
    "        prec_test = precision_score(true_test, pred_test, average='macro', zero_division=0)\n",
    "        rec_test = recall_score(true_test, pred_test, average='macro', zero_division=0)\n",
    "        f1_test = f1_score(true_test, pred_test, average='macro', zero_division=0)\n",
    "        cm_test = confusion_matrix(true_test, pred_test)\n",
    "        print(\"\\nTest Metrics:\")\n",
    "        print(f\"Accuracy : {acc_test:.4f}\")\n",
    "        print(f\"Precision: {prec_test:.4f}\")\n",
    "        print(f\"Recall   : {rec_test:.4f}\")\n",
    "        print(f\"F1 Score : {f1_test:.4f}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(cm_test)\n",
    "    \n",
    "\n",
    "    cbow_path = \"/kaggle/input/a3_models/pytorch/default/1/cbow.pt\"\n",
    "    skipgram_path = \"/kaggle/input/a3_models/pytorch/default/1/skipgram.pt\"\n",
    "    svd_path = \"/kaggle/input/a3_models/pytorch/default/1/svd.pt\"\n",
    "    cbow_static = load_static_embedding_model(cbow_path, device)\n",
    "    skipgram_static = load_static_embedding_model(skipgram_path, device)\n",
    "    svd_static = load_static_embedding_model(svd_path, device)\n",
    "    \n",
    "    \n",
    "    static_classifiers = {\n",
    "        \"cbow\": CBOWClassifier(cbow_static, num_classes=num_classes),\n",
    "        \"skipgram\": SkipgramClassifier(skipgram_static, num_classes=num_classes),\n",
    "        \"svd\": SVDClassifier(svd_static, num_classes=num_classes)\n",
    "    }\n",
    "    \n",
    "    for name, model in static_classifiers.items():\n",
    "        model_path = f\"/kaggle/input/newstatic/pytorch/default/1/classifier2_{name}.pt\"\n",
    "        state_dict = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.to(device)\n",
    "    \n",
    "    \n",
    "    print(\"\\n=== Static Embedding Classifiers Evaluation ===\")\n",
    "    for name, model in static_classifiers.items():\n",
    "        vocab_static = model.vocab\n",
    "        dataset_train_static = NewsDataset(train_df, vocab_static, tokenizer)\n",
    "        dataset_test_static = NewsDataset(test_df, vocab_static, tokenizer)\n",
    "        loader_train_static = DataLoader(dataset_train_static, batch_size=32, shuffle=False, collate_fn=collate_classification, num_workers=4)\n",
    "        loader_test_static = DataLoader(dataset_test_static, batch_size=32, shuffle=False, collate_fn=collate_classification, num_workers=4)\n",
    "        \n",
    "        print(f\"\\n--- Model: {name} ---\")\n",
    "        \n",
    "        true_train, pred_train = evaluate_model(model, loader_train_static, device)\n",
    "        acc_train = accuracy_score(true_train, pred_train)\n",
    "        prec_train = precision_score(true_train, pred_train, average='macro', zero_division=0)\n",
    "        rec_train = recall_score(true_train, pred_train, average='macro', zero_division=0)\n",
    "        f1_train = f1_score(true_train, pred_train, average='macro', zero_division=0)\n",
    "        cm_train = confusion_matrix(true_train, pred_train)\n",
    "        print(\"Train Metrics:\")\n",
    "        print(f\"Accuracy : {acc_train:.4f}\")\n",
    "        print(f\"Precision: {prec_train:.4f}\")\n",
    "        print(f\"Recall   : {rec_train:.4f}\")\n",
    "        print(f\"F1 Score : {f1_train:.4f}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(cm_train)\n",
    "        \n",
    "        \n",
    "        true_test, pred_test = evaluate_model(model, loader_test_static, device)\n",
    "        acc_test = accuracy_score(true_test, pred_test)\n",
    "        prec_test = precision_score(true_test, pred_test, average='macro', zero_division=0)\n",
    "        rec_test = recall_score(true_test, pred_test, average='macro', zero_division=0)\n",
    "        f1_test = f1_score(true_test, pred_test, average='macro', zero_division=0)\n",
    "        cm_test = confusion_matrix(true_test, pred_test)\n",
    "        print(\"\\nTest Metrics:\")\n",
    "        print(f\"Accuracy : {acc_test:.4f}\")\n",
    "        print(f\"Precision: {prec_test:.4f}\")\n",
    "        print(f\"Recall   : {rec_test:.4f}\")\n",
    "        print(f\"F1 Score : {f1_test:.4f}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(cm_test)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6932114,
     "sourceId": 11117359,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 275170,
     "modelInstanceId": 253739,
     "sourceId": 296415,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 279138,
     "modelInstanceId": 257876,
     "sourceId": 301967,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 282831,
     "modelInstanceId": 261688,
     "sourceId": 307006,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 283984,
     "modelInstanceId": 262863,
     "sourceId": 309755,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 284198,
     "modelInstanceId": 263092,
     "sourceId": 310039,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "CondaEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
